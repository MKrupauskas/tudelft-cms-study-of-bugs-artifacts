We have been using reactors fairly extensively and have been seeing what we believe to be significant issues with its use of caching of runners and module loading.     What we see is that when there are many events at the same time we get messages that suggest that the modules cannot be loaded or are not available.   

I believe the issue may be in this code that  is using a CacheDict to cache the various Clients and in the fact that the loader is shared across threads.

In this case two threads can detect that the client is out of date and create a new one at the same time.

```
    if 'runner' not in self.client_cache:
        self.client_cache['runner'] = salt.runner.RunnerClient(self.opts)
    try:
        self.pool.fire_async(self.client_cache['runner'].low, args=(fun, kwargs))
```

It seems that in this can result in the same module being loaded by two threads at the same time and result in unpredictable results.   

Am I missing something or should there be some level of locking to avoid these issues.
