**Description**
A clear and concise description of what the bug is.

Given:
Salt-master behind a firewall with Dynamic IP address. Ports 4505 and 4506 are forwarded to the Salt Stack VM (CentOS 8).

Salt-minions that point to the FQDN salt.someprovider.com.

When the public IP of the firewall changes, changes the DNS entry. After that change, the DNS on the salt-minions gets updated automatically. Even after the update, the minion does not communicate to the master until the service is restarted.


**Setup**
(Please provide relevant configs and/or SLS files (be sure to remove sensitive info. There is no general set-up of Salt.)

Please be as specific as possible and give set-up details.

- [ ] on-prem machine
- [X] VM (CentOS8 on Proxmox (KVM) ) for salt-master
- [ ] VM running on a cloud service, please be explicit and add details
- [ ] container (Kubernetes, Docker, containerd, etc. please specify)
- [ ] or a combination, please be explicit
- [ ] jails if it is FreeBSD

for salt-minions it's VMs in ESXi 6.7 (CentOS 7)


**Steps to Reproduce the behavior**
(Include debug logs if possible and relevant)

Change the public IP of the Salt Mater and try running any command.

**Expected behavior**
A clear and concise description of what you expected to happen.

Expectation is that after the DNS entry gets updated and propagated to all minions to restore "communication" to the master.

**Screenshots**
If applicable, add screenshots to help explain your problem.


Example:

```
[root@localhost ~]# salt -v 'overcast*' pkg.version overcast
Executing job with jid 20220118191518213349
-------------------------------------------
overcast-shephardsbeachresort.hotelwifi.com:
    0.2.4-1
overcast-parkwayflorida.hotelwifi.com:
    3.12.0-1
overcast-shoshonecondominiumshotel.hotelwifi.com:
    4.4.0-1
overcast-mercurerockhampton.hotelwifi.com:
    4.4.0-1
overcast-southgatemotel.hotelwifi.com:
    3.12.0-1
overcast-therownyc.hotelwifi.com:
    4.4.0-1
overcast-hotelmetromilwaukee.hotelwifi.com:
    Minion did not return. [No response]
    The minions may not have all finished running and any remaining minions will return upon completion. To look up the return data for this job later, run the following command:

    salt-run jobs.lookup_jid 20220118191518213349
overcast-dylansfo.hotelwifi.com:
    Minion did not return. [No response]
    The minions may not have all finished running and any remaining minions will return upon completion. To look up the return data for this job later, run the following command:

    salt-run jobs.lookup_jid 20220118191518213349
overcast-reefoceanresort.hotelwifi.com:
    Minion did not return. [No response]
    The minions may not have all finished running and any remaining minions will return upon completion. To look up the return data for this job later, run the following command:

    salt-run jobs.lookup_jid 20220118191518213349
```


**Versions Report**
<details><summary>salt --versions-report</summary>
(Provided by running salt --versions-report. Please also mention any differences in master/minion versions.) 

```
[root@localhost ~]# salt --versions-report
Salt Version:
          Salt: 3004

Dependency Versions:
          cffi: Not Installed
      cherrypy: Not Installed
      dateutil: 2.6.1
     docker-py: Not Installed
         gitdb: Not Installed
     gitpython: Not Installed
        Jinja2: 2.10.1
       libgit2: Not Installed
      M2Crypto: 0.35.2
          Mako: Not Installed
       msgpack: 0.6.2
  msgpack-pure: Not Installed
  mysql-python: Not Installed
     pycparser: Not Installed
      pycrypto: Not Installed
  pycryptodome: Not Installed
        pygit2: Not Installed
        Python: 3.6.8 (default, Oct 19 2021, 05:14:06)
  python-gnupg: Not Installed
        PyYAML: 3.12
         PyZMQ: 19.0.0
         smmap: Not Installed
       timelib: Not Installed
       Tornado: 4.5.3
           ZMQ: 4.3.4

System Versions:
          dist: centos 8
        locale: UTF-8
       machine: x86_64
       release: 4.18.0-348.el8.x86_64
        system: Linux
       version: CentOS Stream 8

```
</details>

**Additional context**
Add any other context about the problem here.
