When doing a cp.get_url with large files (5GB) I encounter a stacktrace:

``` python-traceback
2016-01-15 10:43:52,490 [tornado.application][ERROR ][2619] Uncaught exception
Traceback (most recent call last):
File "/usr/lib64/python2.7/site-packages/tornado/http1connection.py", line 237, in _read_message
delegate.finish()
File "/usr/lib64/python2.7/site-packages/tornado/http1connection.py", line 637, in finish
return self._delegate.finish()
File "/usr/lib64/python2.7/site-packages/tornado/simple_httpclient.py", line 502, in finish
buffer = BytesIO(data) # TODO: don't require one big string?
MemoryError
2016-01-15 10:43:59,482 [salt.minion ][WARNING ][2619] The minion function caused an exception
Traceback (most recent call last):
File "/usr/lib/python2.7/site-packages/salt/minion.py", line 1039, in _thread_return
return_data = func(*args, **kwargs)
File "/usr/lib/python2.7/site-packages/salt/modules/cp.py", line 309, in get_url
return _context_['cp.fileclient'].get_url(path, dest, False, saltenv)
File "/usr/lib/python2.7/site-packages/salt/fileclient.py", line 622, in get_url
**get_kwargs
File "/usr/lib/python2.7/site-packages/salt/utils/http.py", line 438, in query
**req_kwargs
File "/usr/lib64/python2.7/site-packages/tornado/httpclient.py", line 102, in fetch
self._async_client.fetch, request, **kwargs))
File "/usr/lib64/python2.7/site-packages/tornado/ioloop.py", line 444, in run_sync
return future_cell[0].result()
File "/usr/lib64/python2.7/site-packages/tornado/concurrent.py", line 214, in result
raise_exc_info(self._exc_info)
File "<string>", line 3, in raise_xc_info
_QuietException
```

I can see that the bug was fixed for 2015.8.0 ( https://github.com/saltstack/salt/issues/24048 ). However, I can also see that in this issue ( https://github.com/saltstack/salt/pull/27394 ) the code was reverted, with no mention of the initial bug. There should be a way to transfer large files to a minion using salt.
